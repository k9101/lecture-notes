# Lecture 2, May 7, 2018

## Point Estimation
- Used to estimate the model parameters

### Probability Basics
- Chain Rule: $$P(A, B) = P(B \mid A) * P(A)$$
- Bayes Rule: $$P(A \mid B) = \frac{P(A)P(B \mid A)}{P(B)}$$
- Example: What is the prob that a randomly selected individual with a positive test is a drug user?
  - $$P(user \mid positive) = \frac{P(user, positive)}{P(t)} = \frac{P(user, positive)}{P(user, positive) + P(non-user, positive)}$$
  - $$= \frac{P(positive \mid user) P(user)}{P(positive \mid user) P(user) + P(positive \mid non-user) P(non-user)}$$
  - $$= \frac{0.99 * 0.005}{0.99 * 0.005 + (1 - 0.005) * 0.001} \approx 0.332$$
  - Why is the drug 99% specific? Large population, with large number of non-users will bring this down.

### Bias and Variance
- Point Esimator: A single estimation of parameter
  - An estimation of $$\theta$$ is $$\hat{\theta} = 0.1$$
- Bias: $$bias(\hat{\theta}) = E\[\hat{\theta}\] - \theta$$
  - Expectation - the true param
  - $$\theta$$ is fix and unknown, ie. not random
  - If the bias is 0, unbiased
- Variance: $$var(\hat{\theta}) = E\[(\hat{\theta} - E\[\hat{\theta}\])^2\]$$
  - Your dataset is random, may be noisy

- We would prefer a small bias and small variance
  - We would prefer unbiased

### Likelihood Function
- Descrete: $$L(\theta \mid x) = p_\theta (X = x)$$_
  - Use the probability mass function
  - Notice L is a function of $$\theta$$, but pms is a function of x given $$\theta$$
- Continuous: $$L(\theta \mid x) = f_\theta (X = x)$$_
  - Density function
- We would typically use the log-likelihood function
  - $$\log{L(\theta \mid x)}$$
  - Note that log is strictly an increasing function, therefore optimization of log-likelihood is the same as the likelihood

### Maximum Likelihood (ML)
- Observations from some distribution: $$\{x_1, x_2, \ldots, x_N\}$$
- Family of probability distributions: $$p(x; \theta)$$
- Maximize the log-likelihood function to get $$\theta$$
  - Or typically, minimize the negative log-likelihood function

#### Example: Bernoulli Distribution
- Suppose $$P(x_i = 1) = \theta$$
1. Write down the likelihood function
  - $$\Pi_{i=1}^N \theta^{x_i} * (1 - \theta)^{1 - x_i}$$
2. Log Likelihood function
  - $$\sum_{i=1}^N x_i * \log{\theta} + (1 - x_i) * \log{(1 - \theta)}$$
3. Argmax:
  - $$\argmax_\theta \sum_{i=1}^N x_i * \log{\theta} + (1 - x_i) * \log{(1 - \theta)}$$
4. solve Derivative for 0:
  - $$\hat{\theta} = \frac{\sum_i x_i}{N}$$

Suppose that we have a **convex** function $$f$$, and is **differentiable**. A necessary and sufficient condition is to solve $$f'(x) = 0$$
- **Convex**: A function f is convex, if $$f(y) >= f(x) + f'(x)(y - x) \forall (x, y) \in \text{domain of } f$$

#### How many samples are needed?
- Using Hoeffding's Inequality
- Note that $$\theta^\star$$ is the true parameter

#### Example: Gaussian Distribution
- Estimate u and $$\sigma^2$$ using ML
1. Likelihood Function
  - $$\Pi_{i=1}^N \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{(x_i - u)^2}{2\sigma^2}}$$
2. Log-likelihood
  - See the slides
- Solve for u and $$sigma^2$$ by taking partial derivatives
  - Note that u must be done first
- Note that $$\max{f(x)} = \max{c * f(x)}, c > 0$$

#### Limiting property of ML
- If the data was generated by the assumed model, then the ML estimation will converge to the true probability (with enough data points)
- But, in practice data is never generated by an assumed model. There is always some noise, or our assumption can be wrong.

### Maximum A Posteriori (MAP)
- Bayesian Perspective: treat parameter $$\theta$$ as random with prior distribution $$g(\theta)$$ (ex. uniform, gaussian)
  - Therefore, it's not fixed
- Given data x, maximize posterior distribution to get $$\theta$$
  - $$f(\theta \mid x) = \frac{f(\theta, x)}{f(x)} = \frac{f(x \mid \theta) g(\theta)}{\int f(x \mid \theta) g(\theta) d\theta}$$
  - The dinominator is independent of $$\theta$$, only relies on x.
- Difference to ML: multiply by the prior

### Fully Bayesian Approach
- Include all possible values of $$\theta$$
- Typically generalize better with limited training data, high computational cost, usually intractable.
- $$P(x_{N+1} \mid x_1, \ldots, x_N) = \int P(x_1, \ldots, x_{N+1}, \theta) d \theta$$_
- $$\int P(\theta \mid x_1, \ldots, x_N) P(x_{N+1} \mid \theta) d \theta$$_

## Bias-Variance Tradeoff
- Recall that we would like a small bias and small variance, but there are some tradeoffs...
- High bias: Bad assumptions (underfitting)
- High variance: sensitive to small changes in the training set (overfitting)

### Mean Squared Error
- Assume $$y = f(x) + \epsilon$$
- $$E\[(y - \hat{f}(x))^2\] = Bias^2 + Variance + \text{Irreducible Error}$$
  - You can't do anything to remove the noise
  - Noise has mean = 0, variance

### Training and Testing Error
- Divide the dataset into a training and testing part
  - They should both come from independent and identically distributed
  - Important: The test data cannot be used for training the model
- **Objective**: Low test error
  - The more complex the model, the lower the training error will be. But this will likely make the testing error worse as the model fails to generalize.
  - training error is a bad measure because you have the answers, it is only used to construct the model.

## Feature Scaling

- We want to scale our feature set as a part of preprocessing
- Each feature should contribute equally to the model, i.e. features with large values should not be the main predictors.

### Standardization
- Centering: Make sure no features are arbitrarily large
  - Mean 0, variance 1
- Scaling: Make sure all features have roughly the same scale
  - $$X_{i, j} = \frac{X_{i,j} - \hat{X}_j}{\sigma_j}$$
  - $$\bar{X}_j = \frac{1}{n} \sum_{i=1}^n X_{i, j}$$_ (The mean)

When to do standardization
- Some features are significantly smaller or larger than the others.
- Orders of magnitude.

### Normalization
- Choose the mean and maximum of each feature
- Make it between 0 and 1
