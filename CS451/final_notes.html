<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css" />
<div class="markdown-body">
<h1>Final Notes</h1>
<h2>MapReduce Algorithm Design</h2>
<h3>Common Theme</h3>
<p>Parallelization challenges come from (sharing state):</p>
<ul>
<li>Need to communicate partial results</li>
<li>Need to access shared resources</li>
<li><strong>Layer of abstraction</strong>: The datacenter is the computer
<ul>
<li>Allow the developer to avoid system level details.</li>
<li>dev specifies the computation that needs to be performed</li>
<li>framework handles the actual execution</li>
</ul>
</li>
<li>Scale out, not up</li>
<li>assume that components will break</li>
<li>move processing to the data, code is much smaller</li>
<li>process data in sequential order, avoid random access (which is expensive)</li>
</ul>
<h3>MapReduce Runtime</h3>
<ul>
<li>handle scheduling: assign workers to map and reduce tasks</li>
<li>move processes to data
<ul>
<li>Start up worker on nodes that hold the data.</li>
</ul>
</li>
<li>handles synchronization</li>
<li>handling errors and faults</li>
<li>gotchas
<ul>
<li>avoid object creation (expensive)</li>
<li>get data to maps and reducers
<ul>
<li>via job config params</li>
<li>Side data: distributed cache, read from HDFS in setup.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Business Intelligence</h3>
<p>Organizations should retain data resulting from carrying out it's mission. Exploit those insights to benefit the organization.</p>
<h4>Virtuous product cycle: Generate revenue</h4>
<ol>
<li>a useful service</li>
<li>analyze user behaviour to extract insights (data science)</li>
<li>transform insights into actions (data products)</li>
<li>feedback</li>
</ol>
<h3>Cloud Computing</h3>
<ul>
<li>Utility computing: computing resources as a metered service, pay as you go</li>
<li>cloud makes it easier to start companies that generate big data, avoid ownership of the data</li>
<li>everything as a service</li>
</ul>
<h3>Namenode Responsibilities</h3>
<ul>
<li>managing the file system namespace</li>
<li>coordinating file operations</li>
<li>maintaining overall health</li>
</ul>
<p>files are divided into many splits, RecordReaders act as a cursor, passed to the Mappers.</p>
<ul>
<li>the splits can be arbitrary, down the middle of a record</li>
<li>RecordReaders always start reading from a complete block, may keep reading over the edge of a split to capture the last record.</li>
</ul>
<h3>Distributed GroupBy in MapReduce</h3>
<h4>Map side</h4>
<ul>
<li>map outputs are in memory in a circular buffer</li>
<li>when buffer reaches threshold, contents spilled to disk</li>
<li>spills are merged into a single partitioned file (sorted by partition)</li>
<li>combiners run during merges</li>
</ul>
<h4>Reduce Side</h4>
<ul>
<li>map outputs are copied over to reducers</li>
<li>sort is a multi-pass merge of map outputs (in memory, on disk)</li>
<li>combiner runs during the merges</li>
<li>final merge pass goes directly into reducer</li>
</ul>
<h4>Design Patterns</h4>
<ul>
<li>all algs must be expressed in m, r, c, p</li>
<li>no idea when things run, what order, which input a worker is processing</li>
<li>avoid: object creation, buffering</li>
<li>local aggregation: synchronization kills communication, kills performance, reduce the number of intermediate pairs that need to be processed.
<ul>
<li>in-mapper combining: fold combiner into the mapper, preserve state across multiple map calls.
<ul>
<li>pros: speed</li>
<li>cons: need to explicitly manage memory, order-dependent bugs</li>
</ul>
</li>
</ul>
</li>
<li>combiners are optional optimizations, may br run 0, 1, or multiple times
<ul>
<li>should not impact correctness</li>
</ul>
</li>
</ul>
<h5>Pairs vs. Stripes</h5>
<ul>
<li><strong>Pairs:</strong> Utilize the key as a pair, secondary sorting
<ul>
<li>pros: easy to implement + understand</li>
<li>cons: lots of intermediate pairs, combiners dont really work</li>
<li>may need custom sort order, have certain pairs show-up first <code>(a, *)</code>
<ul>
<li>pull values as part of the key for proper sorting</li>
</ul>
</li>
</ul>
</li>
<li><strong>Stripes:</strong> Group pairs into associative array
<ul>
<li>pros: less sorting and shuffling, can use combiners (element-wise operations)</li>
<li>cons: harder to implement, more complicated object, data structure manipulations,</li>
</ul>
</li>
</ul>
<p>tradeoffs:</p>
<ul>
<li>developer code vs. framework (sorting, grouping)</li>
<li>number of kv pairs</li>
<li>size + complexity of each kv pair: de/serialization overhead</li>
</ul>
<table>
<thead>
<tr>
<th>Pairs</th>
<th>Stripes</th>
</tr>
</thead>
<tbody>
<tr>
<td>more kv pairs</td>
<td>less</td>
</tr>
<tr>
<td>less combining</td>
<td>more combining</td>
</tr>
<tr>
<td>more sorting</td>
<td>less sorting + shuffling</td>
</tr>
<tr>
<td>simple reduce aggs</td>
<td>complex (slower) aggs</td>
</tr>
</tbody>
</table>
<h3>Pig</h3>
<ul>
<li>write in a higher level language, run a series of MapReduce jobs.</li>
</ul>
<p>Common model:</p>
<pre><code class="language-pig">LOAD # load from HDFS
FOREACH ... GENERATE # per tuple processing
FILTER # discard unwanted tuples: (map)
GROUP / COGROUP # group tuples
join # relational join (reduce)
STORE # write back to HDFS
</code></pre>
<ul>
<li>extend PIG via user defined functions (UDFs) in any language</li>
</ul>
<h3>Problems with MapReduce</h3>
<ul>
<li>always have to go back to HDFS</li>
<li>slow</li>
<li>Dryad: Graph processing framework
<ul>
<li>abstractions for vertex-to-vertex communication</li>
</ul>
</li>
</ul>
<h2>Spark</h2>
<ul>
<li>
<p>based on <strong>Resilient Distributed Datasets (RDD)</strong></p>
<ul>
<li>immutable, partitioned</li>
<li>perform transformations, lazy</li>
<li>actions, trigger the execution</li>
</ul>
</li>
<li>
<p>RDDs don't have to be written back to HDFS, can chain operations</p>
</li>
<li>
<p>fault tolerance: RDDs can be regenerated from the operations</p>
</li>
<li>
<p>why does it work</p>
<ul>
<li>associativity: group operations in any way: <code>1 + 3 + 2 = (1 + 3) + 2</code></li>
<li>commutativity: swap order of operands however you want: <code>(2 + 1) + 3 = 3 + (2 + 1)</code></li>
</ul>
</li>
</ul>
<h3>Monoids</h3>
<ul>
<li>semigroup: (M, operator)
<ul>
<li><img src="data/final_notes/latex-59267102-e735-4833-acf7-81c6f5ce04ae.png" alt="latex-59267102-e735-4833-acf7-81c6f5ce04ae"></li>
</ul>
</li>
<li>monoid: Semigroup + identity operation
<ul>
<li><img src="data/final_notes/latex-a52425e5-7fc0-44e4-b72d-6e641c61b452.png" alt="latex-a52425e5-7fc0-44e4-b72d-6e641c61b452"></li>
</ul>
</li>
<li>commutative Monoid: monoid + commutativity
<ul>
<li><img src="data/final_notes/latex-0715c96e-cbe7-46c0-8331-7f98b9e73a9b.png" alt="latex-0715c96e-cbe7-46c0-8331-7f98b9e73a9b"></li>
</ul>
</li>
<li>when you can't utilize monoids: sequence computations by sorting</li>
</ul>
<h2>Analyzing Text</h2>
<ul>
<li>Language Models: <img src="data/final_notes/latex-7c16207a-fe5c-4b87-84bf-f121734bbd01.png" alt="latex-7c16207a-fe5c-4b87-84bf-f121734bbd01">_</li>
<li>Use Markov Assumption to limit history to a fixed number of words: <img src="data/final_notes/latex-a2d8accd-53b4-4afb-bd4c-d6be9064e44a.png" alt="latex-a2d8accd-53b4-4afb-bd4c-d6be9064e44a"></li>
<li><img src="data/final_notes/latex-0d72a8cb-f85f-45c3-abad-e8cc4f2a2a51.png" alt="latex-0d72a8cb-f85f-45c3-abad-e8cc4f2a2a51"> unigram language model, <img src="data/final_notes/latex-e3a76a33-8713-4fe3-8998-452737079b0a.png" alt="latex-e3a76a33-8713-4fe3-8998-452737079b0a">: bigrams</li>
<li>Compute <strong>Maximum likelihood estimates (MLE)</strong> (count + divide)
<ul>
<li><img src="data/final_notes/latex-435e345d-bd50-4702-a5c0-544349b3576f.png" alt="latex-435e345d-bd50-4702-a5c0-544349b3576f"></li>
</ul>
</li>
<li><strong>Smoothing</strong>: Want to avoid zero probabilities
<ul>
<li>Laplace: add 1 to all counts</li>
<li>Jelinek-Mercer smoothing: weighted linear combination of lower-order models.</li>
<li>Kneser-Ney: discounted model with special continuouation n-gram model. Number of different contexts <img src="data/final_notes/latex-4cb665ab-0a1b-4d1a-af07-4476d40a9fb8.png" alt="latex-4cb665ab-0a1b-4d1a-af07-4476d40a9fb8"> has appeared in.</li>
<li>Stupid backoff: use the higher order language model if greater than zero, otherwise fallback to lower order models.
<ul>
<li>Solve the problem by throwing lots of data at it.</li>
</ul>
</li>
</ul>
</li>
<li>Bayes rule: <img src="data/final_notes/latex-042a1eff-605e-4889-86bc-ad4988601c96.png" alt="latex-042a1eff-605e-4889-86bc-ad4988601c96"></li>
</ul>
<h2>Document Retreival</h2>
<ul>
<li><strong>ranked retrieval</strong>: Order documents by how likely they are to be relevant.</li>
<li>Partitioning: Scalability</li>
<li>Replication: Redundancy</li>
<li>Caching: Speed</li>
<li>Routing: Load Balancing</li>
</ul>
<h3>TF.IDF Term Weighting</h3>
<ul>
<li>term weights consist of 2 parts: document and collection</li>
<li>high weights for terms that appear many times in a document, terms that appear in many documents should get low weights.</li>
</ul>
<p><img src="data/final_notes/latex-9af68197-14b2-4f93-91df-1d0ff824aa78.png" alt="latex-9af68197-14b2-4f93-91df-1d0ff824aa78"></p>
<h2>Graphs</h2>
<ul>
<li>hard: irregular structure, irregular access patterns</li>
<li>typical alg: local computations at each node, propogate results along the edges</li>
</ul>
<p>Representations:</p>
<ul>
<li><strong>Adjacency Matrix:</strong> nxn square matrix, n=number of verticies, <img src="data/final_notes/latex-2167e5f4-e623-48bf-864c-0dcbf7fbe057.png" alt="latex-2167e5f4-e623-48bf-864c-0dcbf7fbe057">_ iff there is an edge from i to j.
<ul>
<li>intuitive to iterate over rows and columns</li>
<li>lots of wasted space, for sparse graphs. easy to write, hard to run computations</li>
</ul>
</li>
<li><strong>Adjacency List:</strong>
<ul>
<li>Less wasted space, possible to compress. Easy to compute using outlinks (just iterate over the list foreach edge)</li>
<li>hard to compute over inlinks</li>
</ul>
</li>
<li><strong>Edge List:</strong> Explicitly enumerate all of the edge pairs
<ul>
<li>easy to add new edges, just add a pair to the list</li>
<li>waste alot of space.</li>
</ul>
</li>
</ul>
<p>Store undirected graphs, do one of:</p>
<ol>
<li>store both edges, make sure the algorithm de-dups</li>
<li>store as one edge, alg needs to recognize it goes in both directions.</li>
</ol>
<p>Manipulations</p>
<ul>
<li>Invert: <code>flatMap</code> and <code>regroup</code></li>
<li>Adjacency list -&gt; edge list: <code>flatMap</code> over adjacency list and emit tuples</li>
<li>Edge list -&gt; adjacency list: <code>groupby</code></li>
</ul>
<p>Single Source Shortest Path</p>
<ul>
<li>Recall: <strong>Dijkstra</strong>, start at source node, expand the field until the destination is reached.</li>
<li>Define inductivly
<ul>
<li><code>DistanceTo(s) = 0</code> b is reachable from a if b is on adjacency list of a</li>
<li><code>DistanceTo(p) = 1</code> For all nodes p reachable from s</li>
<li><code>DistanceTo(n) = 1 + min(DistanceTo(m), for m in M)</code>: For all nodes n reachable from some other set of nodes M</li>
</ul>
</li>
</ul>
<p>Parallel BFS</p>
<ul>
<li>For all nodes except the start, <img src="data/final_notes/latex-f747f1b9-0bf2-4427-9a20-d22c0eec91b8.png" alt="latex-f747f1b9-0bf2-4427-9a20-d22c0eec91b8"></li>
<li><strong>Mapper</strong>: For each m in adjacency list, emit <code>(m, d+1)</code>, emit the distance to yourself</li>
<li><strong>Sort/Shuffle</strong>: group distances by reachable nodes</li>
<li><strong>Reducer</strong>: Select the minimum distance path for each reachable node, additional book-keeping needed to keep track of the actual path.</li>
<li>Multiple Iterations: each MapReduce job expands the frontier by one step</li>
</ul>
<pre><code class="language-scala">class Mapper {
  def map(id: Long, n: Node) = {
    emit(id, n)
    val d = n.distance
    emit(id, d)
    for (m &lt;- n.adjacenyList) {
      emit(m, d+1)
    }
  }
}

class Reducer {
  def reduce(id: Long, objects: Iterable[Object]) = {
    var min = infinity
    var n = null
    for (d &lt;- objects) {
      if (isNode(d)) n = d
      else if (d &lt; min) min = d
    }
    n.distance = min
    emit(id, n)
  }
}
</code></pre>
<ul>
<li>run job, check for convergence, try again</li>
<li>MapReduce explores all possible paths in parallel, lots of wasted space, we only do useful work at the frontier.</li>
</ul>
<p>Single Source with weighted edges</p>
<ul>
<li>add weight w for each edge in adjacency list</li>
<li>in mapper emit <code>(m, d+w)</code> instead of <code>(m, d+1)</code></li>
<li>need to go through the entire graph</li>
</ul>
<p>Multiple Source shortest Path</p>
<ul>
<li>have an array of sources</li>
<li>Mapper emits an array of distances wrt each source</li>
<li>Reducer finds the minimum for each element in the array</li>
</ul>
<p>Generic Recipie:</p>
<ul>
<li>represent graph as adjacency list</li>
<li>perform local computations in the mapper</li>
<li>pass along partial results via outlinks, use the desination node as the key</li>
<li>perform aggregation in the reducer on inlinks to a node</li>
<li>iterate until convergence, external driver</li>
<li>pass the graph structure between iterations</li>
</ul>
<p>PageRank</p>
<ul>
<li>
<p>Based off of random walks around the web</p>
</li>
<li>
<p>Given page x with n inlinks</p>
<ul>
<li><img src="data/final_notes/latex-28925682-0abd-4b2b-b2e7-697b63605862.png" alt="latex-28925682-0abd-4b2b-b2e7-697b63605862"> is out-degree of t</li>
<li><img src="data/final_notes/latex-331ccd78-73c0-46d9-bbc2-c0a14960e56f.png" alt="latex-331ccd78-73c0-46d9-bbc2-c0a14960e56f"> is the prob of a random jump</li>
<li><img src="data/final_notes/latex-9885251a-83c8-403b-9c32-692941c0246e.png" alt="latex-9885251a-83c8-403b-9c32-692941c0246e"> total number of nodes in the graph</li>
<li><img src="data/final_notes/latex-36a397eb-f8a2-4de5-b096-ab7f2917b0c8.png" alt="latex-36a397eb-f8a2-4de5-b096-ab7f2917b0c8"></li>
<li>Second pass for dangling nodes: <img src="data/final_notes/latex-fe7a4646-a055-4165-99ad-4fe272d1c8e6.png" alt="latex-fe7a4646-a055-4165-99ad-4fe272d1c8e6">
<ul>
<li><img src="data/final_notes/latex-53845c53-282e-423b-91ca-5cd4402c5295.png" alt="latex-53845c53-282e-423b-91ca-5cd4402c5295"> is previous pagerank mass</li>
<li><img src="data/final_notes/latex-561b5b24-0620-46b3-a1df-3efa4aa0a35b.png" alt="latex-561b5b24-0620-46b3-a1df-3efa4aa0a35b"> is the missing PageRank mass</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Convergence criteria</p>
<ul>
<li>iterate until PageRank values don't change</li>
<li>Iterate until PageRank rankings don't change</li>
<li>Fixed number of iterations</li>
</ul>
</li>
<li>
<p>Use log probabilities to avoid small values</p>
</li>
<li>
<p>weighted PageRank</p>
</li>
<li>
<p>Personalized PageRank</p>
</li>
<li>
<p>Spark: <code>join</code>, <code>flatMap</code>, <code>reduceByKey</code></p>
<ul>
<li>cache the adjacency list</li>
<li>Join with PageRank vector</li>
</ul>
</li>
</ul>
<h2>Analyzing Relational Data</h2>
<p>Database Workloads</p>
<ul>
<li><strong>OLTP</strong>: Online Transaction Processing
<ul>
<li>user facing, real-time, low-latency</li>
<li>Application users want fast applications
<ul>
<li>Typical access patterns</li>
<li>random access</li>
<li>writes on small amounts of data</li>
<li>small amounts of data per query</li>
</ul>
</li>
</ul>
</li>
<li><strong>OLAP</strong>: Online Analytical Processing
<ul>
<li>Business intelligence, data mining</li>
<li>batch workloads, less concurrency</li>
<li>Analysts want to be able to analyze large amounts of data
<ul>
<li>Full table scans</li>
<li>lots of joins</li>
<li>large amounts of data per query</li>
</ul>
</li>
</ul>
</li>
<li>Hard for OLTP and OLAP to exist together
<ul>
<li>poor memory management</li>
<li>conflicting data accessing patterns</li>
<li>variable latency</li>
<li><strong>solution</strong> Build a separate data warehouse</li>
<li>OTLP -&gt; ETL -&gt; OLAP
<ul>
<li>Run ETL on some frequency (ex. every night)</li>
<li><strong>Implication</strong>: Analysts are working on old data</li>
<li>Extract</li>
<li>Transform
<ul>
<li>Data cleaning and integrity checking</li>
<li>schema conversion</li>
<li>field transformations</li>
</ul>
</li>
<li>Load</li>
</ul>
</li>
</ul>
</li>
<li><strong>OLAP cubes</strong>: Join tables together, perform operations
<ul>
<li>slice and dice
<ul>
<li>slice the cube into areas that your interested in</li>
<li>ex. take a time slice, only care about the last month</li>
</ul>
</li>
<li>roll-up /down
<ul>
<li>Dimensions have heirarchial structure: time is composed of hours / days / years</li>
<li>Specific products categories / sub-categories</li>
<li>drill down: Stores in Ontario -&gt; Stores in Southern-Ontario -&gt; Stores in Waterloo</li>
</ul>
</li>
<li>pivot
<ul>
<li>Rotate the cube</li>
<li>Sales figures for products and stores, rotate to see changes by month</li>
<li>Perform aggregation along some different axis</li>
</ul>
</li>
<li>Cube materialization
<ul>
<li>lots of joins, group-bys and aggregations</li>
<li>pre-compute parts of the cube</li>
<li>trade-off between time and space</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>What do you do with the data?</p>
<ul>
<li>Report Generation</li>
<li>Dashboards</li>
<li>Ad-hoc analyses
<ul>
<li>Descriptive: What happened / what is happening</li>
<li>Predictive: predict future, unknown events</li>
</ul>
</li>
<li>Data products</li>
</ul>
<p>Why databases (known unknowns)</p>
<ul>
<li>great for structured data, can use schemas!</li>
<li>data is clean</li>
<li>know what queries you want to run on it</li>
</ul>
<p>Why Not databases (unknown unknowns)</p>
<ul>
<li>little to no structure in data</li>
<li>data is messy and noisy</li>
<li>don't know what your looking for</li>
<li>behavioural data</li>
</ul>
<p>Advantages of Hadoop (dataflow language)</p>
<ul>
<li>don't need to know a schema ahead of time</li>
<li>raw scans are the most common operations</li>
<li>many analyses are better formatted imperitevely</li>
<li>much faster data injest rate</li>
</ul>
<p>Utilize both to gain the most benefits and flexibility:
<strong>Data Lake</strong>: Store of raw data
<strong>Data Warehouse</strong>: Structured data</p>
<p>Future: <strong>HTAP</strong>: Hybrid Transactional Analytical Processing</p>
<ul>
<li>avoid the ETL process</li>
<li>Let's analysts work with realtime data</li>
</ul>
<h3>MapReduce algorithms for relational data</h3>
<ul>
<li>Projection (<img src="data/final_notes/latex-cb67c2cf-5053-4c3c-aecd-881d63a2c4ba.png" alt="latex-cb67c2cf-5053-4c3c-aecd-881d63a2c4ba">)
<ul>
<li>Select particular fields for each tuple</li>
<li>Need to keep track of field positions after projections</li>
</ul>
</li>
<li>Selection (<img src="data/final_notes/latex-2bbc5cfa-f1fa-4bfe-9f0f-f26e168ceb69.png" alt="latex-2bbc5cfa-f1fa-4bfe-9f0f-f26e168ceb69">)
<ul>
<li>Process each tuple, emit those that meet some criteria</li>
<li>Pipeline with projections</li>
<li>Performance limited by HDFS throughput
<ul>
<li>speed of encoding/decoding tuples is important</li>
<li>take advantage of compression</li>
</ul>
</li>
</ul>
</li>
<li>Groupby ... Aggregation
<ul>
<li>Some aggregation function</li>
<li>Map over dataset, emit tuples, key by the group by attribute. <strong>Framework handles the actual grouping</strong></li>
<li>Compute the aggregation function in the reducer</li>
<li>Optimize with combiners, IMC</li>
</ul>
</li>
<li>Joins
<ul>
<li>Reduce side (repartition, shuffle join)
<ul>
<li>map over both datasets</li>
<li>emit tuple value with join key as the intermediate key</li>
<li>framework brings together</li>
<li>perform join in reducer</li>
</ul>
</li>
<li>Map Side (sort-merge)
<ul>
<li>both datasets must be copartitioned (partitioned in the same way), allows for parallelization</li>
<li>Map over one dataset, read from the other corresponding partition</li>
<li>no reducer needed</li>
</ul>
</li>
<li>Hash (broadcast, replicated)
<ul>
<li>Load one dataset into memory, keyed by the join key</li>
<li>Read the other dataset, probe for the join key
<ul>
<li>Store R in DistributedCache, progate to all workers</li>
<li>no reducers necessary</li>
</ul>
</li>
<li>Need <code>R &lt;&lt; S</code> and R must fit into memory</li>
<li>variants
<ul>
<li>R and S are co-partitioned: only need to build hash maps for the corresponding partition</li>
<li>striped: If R doesn't fit into memory
<ul>
<li>Divide R into n groups, such that each fit into memory</li>
<li>Perform a hash join for all n</li>
<li>Union the results together</li>
</ul>
</li>
<li>Use a global key-value store (Memcached), prob the key-value store</li>
</ul>
</li>
</ul>
</li>
<li>Preferences (Most, ... ,Least): Hash &gt; Map &gt; Reduce</li>
</ul>
</li>
</ul>
<p>Limitations of Joining</p>
<table>
<thead>
<tr>
<th>Hash</th>
<th>Map</th>
<th>Reduce</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memory</td>
<td>Sort order and partitioning</td>
<td>General purpose</td>
</tr>
</tbody>
</table>
<p>Running SQL-on-Hadoop</p>
<ol>
<li>Build logical plan</li>
<li>optimize logical plan</li>
<li>select physical plan</li>
</ol>
<p>Hadoop Dataware house designs</p>
<ul>
<li>Joins are expensive</li>
<li>Ultimately a time-space trade-off
<ul>
<li>Have more redundant data around in order to save on later joins (save time, waste space)</li>
</ul>
</li>
<li>normalization: factor out redundancy</li>
<li>denormalizations: pre-join to the Facts table in order to save the cost of later joins
<ul>
<li>Denormalize can occur during the ETL process</li>
</ul>
</li>
</ul>
<p>Row vs. column Stores</p>
<ul>
<li>Row store: <code>(a, b, c), (a, b, c), ....</code>
<ul>
<li>Easy to modify a record, in place updates</li>
<li>May need to read un-necessary data during processing</li>
</ul>
</li>
<li>Column store: <code>(a, a, a, a..., ), (b, b, b, ...), (c, c, c, ...)</code>
<ul>
<li>only read the necessary data when processing</li>
<li>tuple writes require multiple operations</li>
<li>tuple updates are complex</li>
<li>better compression, read efficiency, vectorized execution, compiled queries</li>
</ul>
</li>
</ul>
<p>Physical Representation</p>
<ul>
<li>Use binary representations (parqueet, protobuf)</li>
<li>define schemas for binary</li>
<li>Use an index to speed up hadoop, InputSplits on contain blocks that match selection crtieria. Instead of processing everything and thowing away most. Implement at the RecordReader level.</li>
</ul>
<h3>Predictive Analytics</h3>
<ul>
<li>Descriptive Analytics: Describe what is currently happening</li>
<li>Predictive Analytics: Predict future values</li>
<li>Classification: output draw from labels</li>
<li>Data -&gt; Features -&gt; Model -&gt; Optimization</li>
</ul>
<p>Features</p>
<ul>
<li>Dense: most samples contain the features</li>
<li>Sparse: messages that contain specific terms</li>
<li>Gathering labelled data can be a bottleneck
<ul>
<li>crowdsource</li>
<li>Bootstrapping, semi-supervised techniques</li>
<li>Exploiting user behaviour logs: emojis for sentiments</li>
</ul>
</li>
<li>Supervised Binary Classification: restrict output label to binary
<ul>
<li>Extend to multi-class with multiple classifiers
<ul>
<li>1 vs. rest: A or not, B or not, ...</li>
<li>Classifier Cascading: A or Not -&gt; B or Not -&gt; ...
<ul>
<li>Keep going until success</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Minimize some loss function, gradient descent, lower loss over time
<ul>
<li>Gradient descent is first order techniques, use higher order derivatives</li>
</ul>
</li>
<li><strong>Logistic Regression</strong>:
<ul>
<li>Set equal to one: <img src="data/final_notes/latex-bc327dae-28de-4d64-aaa0-1ca0c8d4ad31.png" alt="latex-bc327dae-28de-4d64-aaa0-1ca0c8d4ad31"></li>
<li><img src="data/final_notes/latex-c8600452-1129-407b-8d64-a04c90a29b87.png" alt="latex-c8600452-1129-407b-8d64-a04c90a29b87"></li>
<li><img src="data/final_notes/latex-b3ba0531-cdf8-43e5-89ea-0e2d4089c850.png" alt="latex-b3ba0531-cdf8-43e5-89ea-0e2d4089c850"></li>
<li><img src="data/final_notes/latex-dc753f49-f634-48f3-947b-0b865ea29946.png" alt="latex-dc753f49-f634-48f3-947b-0b865ea29946">
<ul>
<li>Minimize the log likelihood</li>
</ul>
</li>
<li><img src="data/final_notes/latex-dc8e4dd7-a681-49fa-be44-01a6d4f82bc0.png" alt="latex-dc8e4dd7-a681-49fa-be44-01a6d4f82bc0">
<ul>
<li>Utilize the gradient to update weights</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="gradient.png" alt="Gradient Descent"></p>
<pre><code class="language-scala">val points = spark.textFile(...).map(parsePoint).persist()
var w = // random initial vector
for (i &lt;- 1 to ITERATIONS) {
  val gradient = points.map{ p =&gt;
    p.x * (1/(1+exp(-p.y*(w dot p.x)))-1)*p.y
  }.reduce((a,b) =&gt; a+b)
  w -= gradient
}
</code></pre>
<p>Batch Learning: Update the model after considering all training instances
Online Learning: Update the model after considering each randomly selected training example.</p>
<ul>
<li>stocastic gradient descent</li>
<li>Randomly shuffle the training samples</li>
<li>Mini-batching as a middle ground</li>
</ul>
<p>Ensemble Learning: Use multiple independent models to make a prediction</p>
<ul>
<li>Train classifiers on distinct partitions of the data</li>
<li>Combining Predictions
<ul>
<li>Majority Voting: Take the class that most models pick</li>
<li>Simple Weighted Voting: Apply some weights to each prediction</li>
<li>Model Averaging</li>
</ul>
</li>
<li>This works as long as the models are independent. If the errors are uncorrelated then the chances of multiple classifiers being wrong is less likely.</li>
</ul>
</div>
